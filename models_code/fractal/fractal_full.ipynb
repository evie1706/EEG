{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statistics import mean\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.901782</td>\n",
       "      <td>-0.830329</td>\n",
       "      <td>-0.980897</td>\n",
       "      <td>-1.210650</td>\n",
       "      <td>-1.224758</td>\n",
       "      <td>-1.419926</td>\n",
       "      <td>-1.074092</td>\n",
       "      <td>-1.435657</td>\n",
       "      <td>-1.246885</td>\n",
       "      <td>-1.403916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.840534</td>\n",
       "      <td>-2.026269</td>\n",
       "      <td>-2.035501</td>\n",
       "      <td>-0.766744</td>\n",
       "      <td>-1.523765</td>\n",
       "      <td>-1.978816</td>\n",
       "      <td>-0.869867</td>\n",
       "      <td>-0.624911</td>\n",
       "      <td>-0.680300</td>\n",
       "      <td>-0.914486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.320204</td>\n",
       "      <td>-1.623408</td>\n",
       "      <td>-1.431892</td>\n",
       "      <td>-1.526572</td>\n",
       "      <td>-1.251248</td>\n",
       "      <td>-1.418533</td>\n",
       "      <td>-1.513213</td>\n",
       "      <td>-1.356850</td>\n",
       "      <td>-1.489413</td>\n",
       "      <td>-1.228186</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.837937</td>\n",
       "      <td>-1.313365</td>\n",
       "      <td>-1.410132</td>\n",
       "      <td>-1.400176</td>\n",
       "      <td>-1.487766</td>\n",
       "      <td>-1.404723</td>\n",
       "      <td>-1.288202</td>\n",
       "      <td>-1.190974</td>\n",
       "      <td>-1.167914</td>\n",
       "      <td>-1.247068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.415377</td>\n",
       "      <td>-1.589916</td>\n",
       "      <td>-1.634028</td>\n",
       "      <td>-1.491580</td>\n",
       "      <td>-1.620209</td>\n",
       "      <td>-1.544714</td>\n",
       "      <td>-1.448086</td>\n",
       "      <td>-1.537809</td>\n",
       "      <td>-1.251945</td>\n",
       "      <td>-1.101147</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.508961</td>\n",
       "      <td>-1.386820</td>\n",
       "      <td>-1.513522</td>\n",
       "      <td>-1.379455</td>\n",
       "      <td>-1.508229</td>\n",
       "      <td>-1.539795</td>\n",
       "      <td>-1.520027</td>\n",
       "      <td>-1.951767</td>\n",
       "      <td>-1.381643</td>\n",
       "      <td>-1.428457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.423122</td>\n",
       "      <td>-1.452558</td>\n",
       "      <td>-1.510277</td>\n",
       "      <td>-1.284680</td>\n",
       "      <td>-1.437361</td>\n",
       "      <td>-1.409920</td>\n",
       "      <td>-1.221836</td>\n",
       "      <td>-1.057294</td>\n",
       "      <td>-0.721919</td>\n",
       "      <td>-0.696260</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.082744</td>\n",
       "      <td>-1.503672</td>\n",
       "      <td>-1.192596</td>\n",
       "      <td>-1.566609</td>\n",
       "      <td>-1.146985</td>\n",
       "      <td>-1.324853</td>\n",
       "      <td>-1.238634</td>\n",
       "      <td>-1.284644</td>\n",
       "      <td>-1.124432</td>\n",
       "      <td>-1.378407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.251106</td>\n",
       "      <td>-2.087519</td>\n",
       "      <td>-2.080044</td>\n",
       "      <td>-1.635853</td>\n",
       "      <td>-0.872282</td>\n",
       "      <td>-1.528395</td>\n",
       "      <td>-2.354655</td>\n",
       "      <td>-1.568369</td>\n",
       "      <td>-1.451747</td>\n",
       "      <td>-1.226837</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.266992</td>\n",
       "      <td>-0.674705</td>\n",
       "      <td>-1.373643</td>\n",
       "      <td>-0.960445</td>\n",
       "      <td>-1.608378</td>\n",
       "      <td>-1.885847</td>\n",
       "      <td>-1.570633</td>\n",
       "      <td>-1.163434</td>\n",
       "      <td>-1.621390</td>\n",
       "      <td>-1.887396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \n",
       "0 -0.901782 -0.830329 -0.980897 -1.210650 -1.224758 -1.419926 -1.074092  \\\n",
       "1 -1.320204 -1.623408 -1.431892 -1.526572 -1.251248 -1.418533 -1.513213   \n",
       "2 -1.415377 -1.589916 -1.634028 -1.491580 -1.620209 -1.544714 -1.448086   \n",
       "3 -1.423122 -1.452558 -1.510277 -1.284680 -1.437361 -1.409920 -1.221836   \n",
       "4 -1.251106 -2.087519 -2.080044 -1.635853 -0.872282 -1.528395 -2.354655   \n",
       "\n",
       "         7         8         9   ...        54        55        56        57   \n",
       "0 -1.435657 -1.246885 -1.403916  ... -0.840534 -2.026269 -2.035501 -0.766744  \\\n",
       "1 -1.356850 -1.489413 -1.228186  ... -1.837937 -1.313365 -1.410132 -1.400176   \n",
       "2 -1.537809 -1.251945 -1.101147  ... -1.508961 -1.386820 -1.513522 -1.379455   \n",
       "3 -1.057294 -0.721919 -0.696260  ... -1.082744 -1.503672 -1.192596 -1.566609   \n",
       "4 -1.568369 -1.451747 -1.226837  ... -2.266992 -0.674705 -1.373643 -0.960445   \n",
       "\n",
       "         58        59        60        61        62        63  \n",
       "0 -1.523765 -1.978816 -0.869867 -0.624911 -0.680300 -0.914486  \n",
       "1 -1.487766 -1.404723 -1.288202 -1.190974 -1.167914 -1.247068  \n",
       "2 -1.508229 -1.539795 -1.520027 -1.951767 -1.381643 -1.428457  \n",
       "3 -1.146985 -1.324853 -1.238634 -1.284644 -1.124432 -1.378407  \n",
       "4 -1.608378 -1.885847 -1.570633 -1.163434 -1.621390 -1.887396  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"F:\\Alabama_Internship\\EEG\\Deepesh Code\\Datasets\\Dataset_fractal_full_spectrum.xlsx\")\n",
    "# df = Final_df[columns]\n",
    "\n",
    "X = df.iloc[:, 1 : -1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)\n",
    "\n",
    "# X['y'] = y\n",
    "# X['label'] = X['y'].apply(lambda i: str(i))\n",
    "\n",
    "# pca = PCA(n_components=6)\n",
    "# pca_result = pca.fit_transform(X.values)\n",
    "\n",
    "# X['pca-one'] = pca_result[:,0]\n",
    "# X['pca-two'] = pca_result[:,1] \n",
    "# X['pca-three'] = pca_result[:,2]\n",
    "# X['pca-four'] = pca_result[:,3]\n",
    "# X['pca-five'] = pca_result[:,4] \n",
    "# X['pca-six'] = pca_result[:,5]\n",
    "\n",
    "# print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X['y'] = y\n",
    "# X['label'] = X['y'].apply(lambda i: str(i))\n",
    "# plt.figure(figsize=(16,10))\n",
    "# sns.scatterplot(\n",
    "#     x=\"pca-one\", y=\"pca-two\",\n",
    "#     hue=\"y\",\n",
    "#     palette=sns.color_palette(\"hls\", 2),\n",
    "#     data=X,\n",
    "#     legend=\"full\",\n",
    "#     alpha=0.3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_columns = ['pca-one', 'pca-two', 'pca-three', 'pca-four', 'pca-five', 'pca-six']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.901782</td>\n",
       "      <td>-0.830329</td>\n",
       "      <td>-0.980897</td>\n",
       "      <td>-1.210650</td>\n",
       "      <td>-1.224758</td>\n",
       "      <td>-1.419926</td>\n",
       "      <td>-1.074092</td>\n",
       "      <td>-1.435657</td>\n",
       "      <td>-1.246885</td>\n",
       "      <td>-1.403916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.840534</td>\n",
       "      <td>-2.026269</td>\n",
       "      <td>-2.035501</td>\n",
       "      <td>-0.766744</td>\n",
       "      <td>-1.523765</td>\n",
       "      <td>-1.978816</td>\n",
       "      <td>-0.869867</td>\n",
       "      <td>-0.624911</td>\n",
       "      <td>-0.680300</td>\n",
       "      <td>-0.914486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.320204</td>\n",
       "      <td>-1.623408</td>\n",
       "      <td>-1.431892</td>\n",
       "      <td>-1.526572</td>\n",
       "      <td>-1.251248</td>\n",
       "      <td>-1.418533</td>\n",
       "      <td>-1.513213</td>\n",
       "      <td>-1.356850</td>\n",
       "      <td>-1.489413</td>\n",
       "      <td>-1.228186</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.837937</td>\n",
       "      <td>-1.313365</td>\n",
       "      <td>-1.410132</td>\n",
       "      <td>-1.400176</td>\n",
       "      <td>-1.487766</td>\n",
       "      <td>-1.404723</td>\n",
       "      <td>-1.288202</td>\n",
       "      <td>-1.190974</td>\n",
       "      <td>-1.167914</td>\n",
       "      <td>-1.247068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.415377</td>\n",
       "      <td>-1.589916</td>\n",
       "      <td>-1.634028</td>\n",
       "      <td>-1.491580</td>\n",
       "      <td>-1.620209</td>\n",
       "      <td>-1.544714</td>\n",
       "      <td>-1.448086</td>\n",
       "      <td>-1.537809</td>\n",
       "      <td>-1.251945</td>\n",
       "      <td>-1.101147</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.508961</td>\n",
       "      <td>-1.386820</td>\n",
       "      <td>-1.513522</td>\n",
       "      <td>-1.379455</td>\n",
       "      <td>-1.508229</td>\n",
       "      <td>-1.539795</td>\n",
       "      <td>-1.520027</td>\n",
       "      <td>-1.951767</td>\n",
       "      <td>-1.381643</td>\n",
       "      <td>-1.428457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.423122</td>\n",
       "      <td>-1.452558</td>\n",
       "      <td>-1.510277</td>\n",
       "      <td>-1.284680</td>\n",
       "      <td>-1.437361</td>\n",
       "      <td>-1.409920</td>\n",
       "      <td>-1.221836</td>\n",
       "      <td>-1.057294</td>\n",
       "      <td>-0.721919</td>\n",
       "      <td>-0.696260</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.082744</td>\n",
       "      <td>-1.503672</td>\n",
       "      <td>-1.192596</td>\n",
       "      <td>-1.566609</td>\n",
       "      <td>-1.146985</td>\n",
       "      <td>-1.324853</td>\n",
       "      <td>-1.238634</td>\n",
       "      <td>-1.284644</td>\n",
       "      <td>-1.124432</td>\n",
       "      <td>-1.378407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.251106</td>\n",
       "      <td>-2.087519</td>\n",
       "      <td>-2.080044</td>\n",
       "      <td>-1.635853</td>\n",
       "      <td>-0.872282</td>\n",
       "      <td>-1.528395</td>\n",
       "      <td>-2.354655</td>\n",
       "      <td>-1.568369</td>\n",
       "      <td>-1.451747</td>\n",
       "      <td>-1.226837</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.266992</td>\n",
       "      <td>-0.674705</td>\n",
       "      <td>-1.373643</td>\n",
       "      <td>-0.960445</td>\n",
       "      <td>-1.608378</td>\n",
       "      <td>-1.885847</td>\n",
       "      <td>-1.570633</td>\n",
       "      <td>-1.163434</td>\n",
       "      <td>-1.621390</td>\n",
       "      <td>-1.887396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \n",
       "0 -0.901782 -0.830329 -0.980897 -1.210650 -1.224758 -1.419926 -1.074092  \\\n",
       "1 -1.320204 -1.623408 -1.431892 -1.526572 -1.251248 -1.418533 -1.513213   \n",
       "2 -1.415377 -1.589916 -1.634028 -1.491580 -1.620209 -1.544714 -1.448086   \n",
       "3 -1.423122 -1.452558 -1.510277 -1.284680 -1.437361 -1.409920 -1.221836   \n",
       "4 -1.251106 -2.087519 -2.080044 -1.635853 -0.872282 -1.528395 -2.354655   \n",
       "\n",
       "         7         8         9   ...        54        55        56        57   \n",
       "0 -1.435657 -1.246885 -1.403916  ... -0.840534 -2.026269 -2.035501 -0.766744  \\\n",
       "1 -1.356850 -1.489413 -1.228186  ... -1.837937 -1.313365 -1.410132 -1.400176   \n",
       "2 -1.537809 -1.251945 -1.101147  ... -1.508961 -1.386820 -1.513522 -1.379455   \n",
       "3 -1.057294 -0.721919 -0.696260  ... -1.082744 -1.503672 -1.192596 -1.566609   \n",
       "4 -1.568369 -1.451747 -1.226837  ... -2.266992 -0.674705 -1.373643 -0.960445   \n",
       "\n",
       "         58        59        60        61        62        63  \n",
       "0 -1.523765 -1.978816 -0.869867 -0.624911 -0.680300 -0.914486  \n",
       "1 -1.487766 -1.404723 -1.288202 -1.190974 -1.167914 -1.247068  \n",
       "2 -1.508229 -1.539795 -1.520027 -1.951767 -1.381643 -1.428457  \n",
       "3 -1.146985 -1.324853 -1.238634 -1.284644 -1.124432 -1.378407  \n",
       "4 -1.608378 -1.885847 -1.570633 -1.163434 -1.621390 -1.887396  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = X[pca_columns]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Participants_count = len(df.index)//2\n",
    "\n",
    "LR_scores = []\n",
    "XGB_scores = []\n",
    "KNN_scores = []\n",
    "SVM_scores = []\n",
    "KSVM_scores = []\n",
    "NB_scores = []\n",
    "DTC_scores = []\n",
    "RFC_scores = []\n",
    "Model_scores_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Leave one out cross validation (LOOCV method), drop out the pre and post info related to one participant, train the model using the remaining data. Test the model using the info which was dropped during the training stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(Participants_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Participants_count):\n",
    "\n",
    "    X_train = X.drop(labels = [i, i + Participants_count], axis=0)\n",
    "    y_train = y.drop(labels = [i, i + Participants_count], axis=0)\n",
    "    X_test = X.iloc[[i, i + Participants_count],:] \n",
    "    y_test = y.iloc[[i, i + Participants_count],:] \n",
    "\n",
    "    if(i==0):\n",
    "        X_train.to_excel(\"X_dataframe.xlsx\")\n",
    "        y_train.to_excel(\"y_dataframe.xlsx\")\n",
    "\n",
    "    # Feature Scaling\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "\n",
    "    # PCA - Principle Component Analysis\n",
    "\n",
    "    #pca = PCA(n_components = 0.95)\n",
    "    #X_train = pca.fit_transform(X_train)\n",
    "    #X_test = pca.transform(X_test)\n",
    "    #explained_variance = pca.explained_variance_ratio_\n",
    "    #print(explained_variance)\n",
    "\n",
    "    # LDA - Linear Discriminant Analysis\n",
    "\n",
    "    #lda = LDA(n_components = 1)\n",
    "    #X_train = lda.fit_transform(X_train,y_train)\n",
    "    #X_test = lda.transform(X_test)\n",
    "\n",
    "    # ML Models Accuracy Computation\n",
    "\n",
    "    LR_classifier = LogisticRegression(random_state = 0)\n",
    "    LR_classifier.fit(X_train, y_train)\n",
    "    LR_scores.append(LR_classifier.score(X_test,y_test))\n",
    "\n",
    "    XGB_classifier = XGBClassifier()\n",
    "    XGB_classifier.fit(X_train, y_train)\n",
    "    XGB_scores.append(XGB_classifier.score(X_test,y_test))\n",
    "    #plt.bar(range(len(XGB_classifier.feature_importances_)), XGB_classifier.feature_importances_)\n",
    "    #plt.show()\n",
    "\n",
    "    KNN_classifier = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2)\n",
    "    KNN_classifier.fit(X_train, y_train)\n",
    "    KNN_scores.append(KNN_classifier.score(X_test,y_test))\n",
    "\n",
    "    SVM_classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "    SVM_classifier.fit(X_train, y_train)\n",
    "    SVM_scores.append(SVM_classifier.score(X_test,y_test))\n",
    "\n",
    "    KSVM_classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "    KSVM_classifier.fit(X_train, y_train)\n",
    "    KSVM_scores.append(KSVM_classifier.score(X_test,y_test))\n",
    "\n",
    "    NB_classifier = GaussianNB()\n",
    "    NB_classifier.fit(X_train, y_train)\n",
    "    NB_scores.append(NB_classifier.score(X_test,y_test))\n",
    "\n",
    "    DTC_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    DTC_classifier.fit(X_train, y_train)\n",
    "    DTC_scores.append(DTC_classifier.score(X_test,y_test))\n",
    "\n",
    "    RFC_classifier = RandomForestClassifier(random_state=0)\n",
    "    RFC_classifier.fit(X_train, y_train)\n",
    "    RFC_scores.append(RFC_classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print out the mean of the accuracies obtained through each of the ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score : 0.475\n",
      "XG Boost Score : 0.45\n",
      "KNN Score : 0.5\n",
      "SVM Score : 0.5\n",
      "Kernel SVM Score : 0.525\n",
      "Naive Bayes Score : 0.6\n",
      "Decision Trees Classifier Score : 0.6\n",
      "Random Forest Classifier Score : 0.525\n"
     ]
    }
   ],
   "source": [
    "model_str = [\"Logistic Regression\",\"XG Boost\", \"KNN\", \"SVM\", \"Kernel SVM\", \"Naive Bayes\", \"Decision Trees Classifier\", \"Random Forest Classifier\"]\n",
    "\n",
    "Model_scores_list.append(LR_scores)\n",
    "Model_scores_list.append(XGB_scores)\n",
    "Model_scores_list.append(KNN_scores)\n",
    "Model_scores_list.append(SVM_scores)\n",
    "Model_scores_list.append(KSVM_scores)\n",
    "Model_scores_list.append(NB_scores)\n",
    "Model_scores_list.append(DTC_scores)\n",
    "Model_scores_list.append(RFC_scores)\n",
    "\n",
    "for i in range(len(model_str)):\n",
    "\n",
    "    print(model_str[i] + \" Score : \" + str(mean(Model_scores_list[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
